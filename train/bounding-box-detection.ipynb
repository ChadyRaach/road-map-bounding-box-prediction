{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bounding-box-detection.ipynb","provenance":[{"file_id":"11_DBWaAhqTpLriro1Ykij5A2XG8pGFxc","timestamp":1589017028054},{"file_id":"1BhcQn6rWsGWmbCu6kbKMtsVai83w5IXX","timestamp":1588959021869},{"file_id":"1hruZwv6VS43yRiSHyaHvqbB_h38M4Lm_","timestamp":1588951517397}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"osvW65pTyzJr","colab_type":"code","outputId":"8d89f441-bc4e-48ac-dfb5-70f77bbc56b6","executionInfo":{"status":"ok","timestamp":1589215943184,"user_tz":240,"elapsed":1045,"user":{"displayName":"Jatin Khilnani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJJnAJAff4HmGKmHnjwHe8kB5VFSQ83yA-vEWXhhMypP8zENG1Dsr0IOFJj4nQvUqiYQHti6_Vu6lCF5lOV6Uv_V8U-pA7cNrC3-Jt-V4LDKZ6TMO44LdxHyZPTkJNHlQwBphNnsW_gd9vNfxPxWYQY-0cJ94v05LAKRigbPItOd9E3CeT9It4WOiWOr37MC3dQZgkRkkt_XJkcqsZRdGxixln0cFTKY-MY535Uuvv3jS7qFR1IV_gtJE1POwpVVGraZsxkWHc2s96O-NQiTKuk6zIi4BlgSZIALN0kjU8lRsnyBScq_djiBAzCE8AKSTm3r9N-ozn30uY7N7SKth0mNzVvxAqZsv2mxdgmuYcoW03RTPMD2BDiYCQNyqhXGzmXQI-qEPDGFQnvdCffZ6ffvRJthVcrITSYYl7JGSZn8EMFygSokdcaDAQqRJ73HwfYEMZiyEoMBDL-m3bMQOosXshsw5jaUlcPXY5npq0sSMFAUpmP56pONADfGi4eo9FT-s5ZBfdMi9ODLVOFSha6S1asf5CSVOBMTlRJo1OZ0KquT-cw0GIYA6YvtLFLoRm1nXu_SHFqDzHZw769tHblh1FkUxcIhIomYvzWnsBH1NLpBPzUoQW6Zmne_exk7KaRo4pkI5DFeX5LSb-do7w1W29Q5a8J_Cnei9iIv-HzEENDaIir_GzioP3WGWBHtUtM6IcJ-amEiGwKKI1LSKal14G2j9PZpk_6VPY5Ul2BSlYSnf2eqPHGMMgsKVjbUB2qw=s64","userId":"07515810133039436777"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Mount drive to save model\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v7Fh-qPSk1v7","colab_type":"code","outputId":"451b4db9-d0e7-4e7d-fe14-9e3ddd227337","executionInfo":{"status":"ok","timestamp":1589216026049,"user_tz":240,"elapsed":82657,"user":{"displayName":"Jatin Khilnani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJJnAJAff4HmGKmHnjwHe8kB5VFSQ83yA-vEWXhhMypP8zENG1Dsr0IOFJj4nQvUqiYQHti6_Vu6lCF5lOV6Uv_V8U-pA7cNrC3-Jt-V4LDKZ6TMO44LdxHyZPTkJNHlQwBphNnsW_gd9vNfxPxWYQY-0cJ94v05LAKRigbPItOd9E3CeT9It4WOiWOr37MC3dQZgkRkkt_XJkcqsZRdGxixln0cFTKY-MY535Uuvv3jS7qFR1IV_gtJE1POwpVVGraZsxkWHc2s96O-NQiTKuk6zIi4BlgSZIALN0kjU8lRsnyBScq_djiBAzCE8AKSTm3r9N-ozn30uY7N7SKth0mNzVvxAqZsv2mxdgmuYcoW03RTPMD2BDiYCQNyqhXGzmXQI-qEPDGFQnvdCffZ6ffvRJthVcrITSYYl7JGSZn8EMFygSokdcaDAQqRJ73HwfYEMZiyEoMBDL-m3bMQOosXshsw5jaUlcPXY5npq0sSMFAUpmP56pONADfGi4eo9FT-s5ZBfdMi9ODLVOFSha6S1asf5CSVOBMTlRJo1OZ0KquT-cw0GIYA6YvtLFLoRm1nXu_SHFqDzHZw769tHblh1FkUxcIhIomYvzWnsBH1NLpBPzUoQW6Zmne_exk7KaRo4pkI5DFeX5LSb-do7w1W29Q5a8J_Cnei9iIv-HzEENDaIir_GzioP3WGWBHtUtM6IcJ-amEiGwKKI1LSKal14G2j9PZpk_6VPY5Ul2BSlYSnf2eqPHGMMgsKVjbUB2qw=s64","userId":"07515810133039436777"}},"colab":{"base_uri":"https://localhost:8080/","height":182}},"source":["! git clone https://github.com/craach/road-map-bounding-box-prediction.git\n","%cd road-map-bounding-box-prediction"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into 'project'...\n","remote: Enumerating objects: 69, done.\u001b[K\n","remote: Counting objects: 100% (69/69), done.\u001b[K\n","remote: Compressing objects: 100% (55/55), done.\u001b[K\n","remote: Total 121922 (delta 40), reused 27 (delta 9), pack-reused 121853\u001b[K\n","Receiving objects: 100% (121922/121922), 1.34 GiB | 26.74 MiB/s, done.\n","Resolving deltas: 100% (40/40), done.\n","Checking out files: 100% (104847/104847), done.\n","/content/project/project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2S2bmHIUkwg6","colab_type":"code","colab":{}},"source":["import os\n","import random\n","import numpy as np\n","import pandas as pd\n","import matplotlib\n","import matplotlib.pyplot as plt \n","matplotlib.rcParams['figure.figsize'] = [5, 5] \n","matplotlib.rcParams['figure.dpi'] = 200\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","from data_helper import UnlabeledDataset, LabeledDataset\n","from google.colab.patches import cv2_imshow\n","from helper import collate_fn, draw_box"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7uE6DXoMmEn_","colab_type":"code","colab":{}},"source":["random.seed(0)\n","np.random.seed(0)\n","torch.manual_seed(0)\n","\n","image_folder = 'data'\n","annotation_csv = 'data/annotation.csv'\n","\n","# All the images are saved in image_folder\n","# All the labels are saved in the annotation_csv file image_folder = 'data'\n","annotation_csv = 'data/annotation.csv'\n","\n","# You shouldn't change the unlabeled_scene_index\n","# The first 106 scenes are unlabeled\n","unlabeled_scene_index = np.arange(106)\n","# The scenes from 106 - 133 are labeled\n","# You should devide the labeled_scene_index into two subsets (training and validation)\n","labeled_scene_train_index = np.arange(106, 130)\n","labeled_scene_validation_index = np.arange(130, 134)\n","transform = torchvision.transforms.ToTensor()\n","\n","device = \"cuda:0\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cf_fH_ehmLnA","colab_type":"code","colab":{}},"source":["# The full road model holds and image model (ResNet18), and applies that\n","# image model to each of the 6 road images.\n","MAX_OBJECTS = 1\n","NUM_CLASSES = 9\n","\n","class BoundingBoxModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.image_model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', \n","                                          pretrained=False)\n","        \n","        self.fc1 = nn.Linear(6000, 1000)\n","        # self.certainty_fc2 = nn.Linear(1000, MAX_OBJECTS)\n","        self.fc2 = nn.Linear(1000, MAX_OBJECTS * 8 + MAX_OBJECTS * NUM_CLASSES)\n","    \n","    \n","    def forward(self, x):\n","        features = []\n","        for im in x:\n","            features.append(self.image_model(im))\n","        x = torch.cat(features, dim=1)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.fc2(x)\n","        return x.reshape([-1, MAX_OBJECTS, NUM_CLASSES + 8])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E2crsEcmmR3i","colab_type":"code","colab":{}},"source":["# TODO: Replace with buit-in function\n","def box_dist(box1, box2):\n","  return torch.sum((box1.reshape(2,4) - box2) ** 2)\n","\n","# Match predictions with closest labels\n","def match_outputs(box_preds, box_labels):\n","  match_set = set(range(len((box_labels))))\n","  matches = []\n","  loss = 0.0\n","  for i, pred in enumerate(box_preds):\n","    min_dist = -1\n","    min_j = 0\n","    for j in match_set:\n","      d = box_dist(pred[:8], box_labels[j])\n","      if d < min_dist or min_dist < 0:\n","        min_j = j\n","        min_dist = d\n","    match_set.remove(min_j)\n","    matches.append(min_j)\n","    loss += min_dist\n","  return loss, matches\n","\n","\n","def train(model, optimizer, trainloader, validationloader, batch_size, version):\n","    fig, ax = plt.subplots()\n","    epochs = 75\n","    ce_loss = nn.CrossEntropyLoss()\n","\n","    metrics_dict = {}\n","    metrics_dict[\"train\"] = {}\n","    metrics_dict[\"val\"] = {}\n","    metrics_dict[\"train\"][\"loss\"] = {}\n","    metrics_dict[\"val\"][\"loss\"] = {}\n","    metrics_dict[\"train\"][\"loss\"][\"epochwise\"] = []\n","    metrics_dict[\"val\"][\"loss\"][\"epochwise\"] = []\n","\n","    # weight of label loss vs. positional loss\n","    lmbda = 100\n","    for ep in range(epochs):\n","      total_loss = 0.0\n","      j = 0\n","      for sample, target, road_image, extra in trainloader:\n","        optimizer.zero_grad()\n","        sample_batch = torch.stack(sample).permute(1, 0, 2, 3, 4)\n","        sample_batch = sample_batch.to(device)\n","        preds = model(sample_batch)\n","        dist_batch_loss = 0.0\n","        label_batch_loss = 0.0\n","        for i, pred in enumerate(preds):\n","          targ = target[i]['bounding_box']\n","          targ = targ.to(device)\n","          dist_loss, matches = match_outputs(pred, targ)\n","          dist_batch_loss += dist_loss\n","          matched_targ = torch.index_select(target[i]['category'].to(device), 0, torch.Tensor(matches).to(device).long())\n","          label_batch_loss += ce_loss(pred[:, 8:17], matched_targ)\n","        l = dist_batch_loss +  lmbda * label_batch_loss                  \n","        l.backward()\n","        optimizer.step()\n","        total_loss += l\n","        if j % 20 == 0:\n","          print(\"epoch {}, iter {}: {}\".format(ep, j, l))\n","        j += 1\n","        \n","      avg_loss = total_loss / j\n","      metrics_dict[\"train\"][\"loss\"][\"epochwise\"].append(avg_loss)  \n","\n","      # Save model\n","      torch.save({\n","        'epoch': ep,\n","        'model_state_dict': model.state_dict(),\n","        'full_metrics': metrics_dict\n","        }, '/content/drive/My Drive/1008-competition/model_run/BoundingBoxModel/detect_version-{}_epoch-{}.pth'.format(version, ep))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NvyS_j5lmUQ7","colab_type":"code","outputId":"bfe16be4-ceab-4013-ade9-80879b826333","executionInfo":{"status":"error","timestamp":1589224035862,"user_tz":240,"elapsed":2028564,"user":{"displayName":"Jatin Khilnani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJJnAJAff4HmGKmHnjwHe8kB5VFSQ83yA-vEWXhhMypP8zENG1Dsr0IOFJj4nQvUqiYQHti6_Vu6lCF5lOV6Uv_V8U-pA7cNrC3-Jt-V4LDKZ6TMO44LdxHyZPTkJNHlQwBphNnsW_gd9vNfxPxWYQY-0cJ94v05LAKRigbPItOd9E3CeT9It4WOiWOr37MC3dQZgkRkkt_XJkcqsZRdGxixln0cFTKY-MY535Uuvv3jS7qFR1IV_gtJE1POwpVVGraZsxkWHc2s96O-NQiTKuk6zIi4BlgSZIALN0kjU8lRsnyBScq_djiBAzCE8AKSTm3r9N-ozn30uY7N7SKth0mNzVvxAqZsv2mxdgmuYcoW03RTPMD2BDiYCQNyqhXGzmXQI-qEPDGFQnvdCffZ6ffvRJthVcrITSYYl7JGSZn8EMFygSokdcaDAQqRJ73HwfYEMZiyEoMBDL-m3bMQOosXshsw5jaUlcPXY5npq0sSMFAUpmP56pONADfGi4eo9FT-s5ZBfdMi9ODLVOFSha6S1asf5CSVOBMTlRJo1OZ0KquT-cw0GIYA6YvtLFLoRm1nXu_SHFqDzHZw769tHblh1FkUxcIhIomYvzWnsBH1NLpBPzUoQW6Zmne_exk7KaRo4pkI5DFeX5LSb-do7w1W29Q5a8J_Cnei9iIv-HzEENDaIir_GzioP3WGWBHtUtM6IcJ-amEiGwKKI1LSKal14G2j9PZpk_6VPY5Ul2BSlYSnf2eqPHGMMgsKVjbUB2qw=s64","userId":"07515810133039436777"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Train\n","batch_size=8\n","version = 1\n","labeled_trainset = LabeledDataset(image_folder=image_folder,\n","                                      annotation_file=annotation_csv,\n","                                      scene_index=labeled_scene_train_index,\n","                                      transform=transform,\n","                                      extra_info=True)\n","trainloader = torch.utils.data.DataLoader(labeled_trainset, \n","                                          batch_size=batch_size, \n","                                          shuffle=True, \n","                                          num_workers=8, \n","                                          collate_fn=collate_fn)\n","labeled_validationset = LabeledDataset(image_folder=image_folder,\n","                                      annotation_file=annotation_csv,\n","                                      scene_index=labeled_scene_validation_index,\n","                                      transform=transform,\n","                                      extra_info=True)\n","validationloader = torch.utils.data.DataLoader(labeled_trainset, \n","                                          batch_size=batch_size, \n","                                          shuffle=True, \n","                                          num_workers=8, \n","                                          collate_fn=collate_fn)\n","model = BoundingBoxModel().to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, betas = (0.9,0.999))\n","train(model, optimizer, trainloader, validationloader, batch_size, version)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"],"name":"stderr"},{"output_type":"stream","text":["torch.Size([8, 1, 17])\n","tensor(5278.8920, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(18.5169, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 0, iter 0: 7130.58246876592\n","torch.Size([8, 1, 17])\n","tensor(1581.6761, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(4.6799, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 0, iter 20: 2049.665430928382\n","torch.Size([8, 1, 17])\n","tensor(6436.4434, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(9.3387, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 0, iter 40: 7370.314780413856\n","torch.Size([8, 1, 17])\n","tensor(2031.9162, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(8.9251, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 0, iter 60: 2924.4285037835825\n","torch.Size([8, 1, 17])\n","tensor(309.9705, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.2900, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 0, iter 80: 338.9733594734882\n","torch.Size([8, 1, 17])\n","tensor(1314.0119, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(3.3305, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 0, iter 100: 1647.0661786971218\n","torch.Size([8, 1, 17])\n","tensor(3750.6741, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(10.4269, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 0, iter 120: 4793.368397764445\n","torch.Size([8, 1, 17])\n","tensor(997.2744, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 0, iter 140: 1016.4496605120601\n","torch.Size([8, 1, 17])\n","tensor(2427.9844, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(6.9818, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 0, iter 160: 3126.1670693706283\n","torch.Size([8, 1, 17])\n","tensor(1120.0447, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(1.0457, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 0, iter 180: 1224.6136464430263\n","torch.Size([8, 1, 17])\n","tensor(529.5965, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(1.7349, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 0, iter 200: 703.0848761925471\n","torch.Size([8, 1, 17])\n","tensor(1054.6225, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(1.0682, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 0, iter 220: 1161.4406047951798\n","torch.Size([8, 1, 17])\n","tensor(885.0804, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 0, iter 240: 918.1580055528399\n","torch.Size([8, 1, 17])\n","tensor(716.4859, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(1.5165, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 0, iter 260: 868.1330307950541\n","torch.Size([8, 1, 17])\n","tensor(417.3785, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.3756, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 0, iter 280: 454.94268961235224\n","torch.Size([8, 1, 17])\n","tensor(486.0045, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.1129, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 0, iter 300: 497.29397809933585\n","torch.Size([8, 1, 17])\n","tensor(642.1022, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.1827, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 0, iter 320: 660.3748490195092\n","torch.Size([8, 1, 17])\n","tensor(1524.2321, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.3215, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 0, iter 340: 1556.3818601666524\n","torch.Size([8, 1, 17])\n","tensor(723.6594, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.1053, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 0, iter 360: 734.1869044729884\n","torch.Size([8, 1, 17])\n","tensor(1815.1376, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.2805, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 1, iter 0: 1843.1862107909353\n","torch.Size([8, 1, 17])\n","tensor(654.4726, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(1.0699, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 1, iter 20: 761.4636039392673\n","torch.Size([8, 1, 17])\n","tensor(809.5255, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.2606, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 1, iter 40: 835.5879555094656\n","torch.Size([8, 1, 17])\n","tensor(348.8711, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.5657, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 1, iter 60: 405.4401711181508\n","torch.Size([8, 1, 17])\n","tensor(2403.1094, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(1.2720, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 1, iter 80: 2530.3141654307797\n","torch.Size([8, 1, 17])\n","tensor(424.6698, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.7013, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 1, iter 100: 494.79979699232143\n","torch.Size([8, 1, 17])\n","tensor(2015.2862, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(1.1535, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 1, iter 120: 2130.632565646626\n","torch.Size([8, 1, 17])\n","tensor(530.3734, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(3.9040, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 1, iter 140: 920.772958436098\n","torch.Size([8, 1, 17])\n","tensor(1177.9949, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(8.5298, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 1, iter 160: 2030.9754877766566\n","torch.Size([8, 1, 17])\n","tensor(506.5974, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 1, iter 180: 543.6123555130517\n","torch.Size([8, 1, 17])\n","tensor(293.8505, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(9.3509, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 1, iter 200: 1228.938921934291\n","torch.Size([8, 1, 17])\n","tensor(2684.2226, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(7.0662, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 1, iter 220: 3390.8468294750437\n","torch.Size([8, 1, 17])\n","tensor(1902.8272, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(6.4159, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 1, iter 240: 2544.421089750549\n","torch.Size([8, 1, 17])\n","tensor(2933.2446, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(22.0335, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 1, iter 260: 5136.590523856694\n","torch.Size([8, 1, 17])\n","tensor(1475.2505, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(4.4178, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 1, iter 280: 1917.0338100619492\n","torch.Size([8, 1, 17])\n","tensor(1337.1395, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(6.1184, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 1, iter 300: 1948.9758154550373\n","torch.Size([8, 1, 17])\n","tensor(402.5371, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0259, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 1, iter 320: 405.12315474980016\n","torch.Size([8, 1, 17])\n","tensor(597.5209, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.2078, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 1, iter 340: 618.2985985228601\n","torch.Size([8, 1, 17])\n","tensor(814.1361, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.7297, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 1, iter 360: 887.1079903374169\n","torch.Size([8, 1, 17])\n","tensor(1733.4079, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(7.3460, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 2, iter 0: 2468.004903018652\n","torch.Size([8, 1, 17])\n","tensor(859.4843, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(3.7731, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 2, iter 20: 1236.7964381462075\n","torch.Size([8, 1, 17])\n","tensor(365.1168, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.7768, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 2, iter 40: 442.79668548534886\n","torch.Size([8, 1, 17])\n","tensor(1394.1021, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(3.7673, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 2, iter 60: 1770.8352282152448\n","torch.Size([8, 1, 17])\n","tensor(571.0372, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(5.7922, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 2, iter 80: 1150.2613357710225\n","torch.Size([8, 1, 17])\n","tensor(804.2880, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(2.9540, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 2, iter 100: 1099.6831620221799\n","torch.Size([8, 1, 17])\n","tensor(722.4665, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(5.5167, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 2, iter 120: 1274.1408805886504\n","torch.Size([8, 1, 17])\n","tensor(411.6186, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.4799, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 2, iter 140: 459.60920477256775\n","torch.Size([8, 1, 17])\n","tensor(488.7700, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.7051, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 2, iter 160: 559.2816687860814\n","torch.Size([8, 1, 17])\n","tensor(509.7409, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.6875, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 2, iter 180: 578.4942076916328\n","torch.Size([8, 1, 17])\n","tensor(2437.3932, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(8.1143, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 2, iter 200: 3248.827955388009\n","torch.Size([8, 1, 17])\n","tensor(534.5129, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(2.4916, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 2, iter 220: 783.6715799157372\n","torch.Size([8, 1, 17])\n","tensor(989.0915, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.1714, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 2, iter 240: 1006.2295817544309\n","torch.Size([8, 1, 17])\n","tensor(434.7529, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(1.1328, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 2, iter 260: 548.0292412143451\n","torch.Size([8, 1, 17])\n","tensor(338.5547, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.4050, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 2, iter 280: 379.0499920624176\n","torch.Size([8, 1, 17])\n","tensor(349.5517, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.3592, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 2, iter 300: 385.46765042082126\n","torch.Size([8, 1, 17])\n","tensor(873.0307, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(3.0216, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 2, iter 320: 1175.1890152722144\n","torch.Size([8, 1, 17])\n","tensor(324.6538, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.8465, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 2, iter 340: 409.3064878040575\n","torch.Size([8, 1, 17])\n","tensor(1195.7209, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(4.7385, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 2, iter 360: 1669.5726678592314\n","torch.Size([8, 1, 17])\n","tensor(294.5162, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(2.0545, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 3, iter 0: 499.97020964120935\n","torch.Size([8, 1, 17])\n","tensor(834.6683, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(4.2253, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 3, iter 20: 1257.1952100124504\n","torch.Size([8, 1, 17])\n","tensor(1668.3252, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(9.6088, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 3, iter 40: 2629.204931696785\n","torch.Size([8, 1, 17])\n","tensor(1313.7161, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.7898, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 3, iter 60: 1392.694799816523\n","torch.Size([8, 1, 17])\n","tensor(753.8866, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 3, iter 80: 780.6159488298753\n","torch.Size([8, 1, 17])\n","tensor(887.3318, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.7852, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 3, iter 100: 965.8522992509104\n","torch.Size([8, 1, 17])\n","tensor(858.6390, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(4.9499, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 3, iter 120: 1353.628037659129\n","torch.Size([8, 1, 17])\n","tensor(309.4047, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.2324, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 3, iter 140: 332.64721918059627\n","torch.Size([8, 1, 17])\n","tensor(1121.9306, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(3.4367, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 3, iter 160: 1465.5981156997836\n","torch.Size([8, 1, 17])\n","tensor(969.5411, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(3.1626, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 3, iter 180: 1285.8040233072857\n","torch.Size([8, 1, 17])\n","tensor(1226.7170, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 3, iter 200: 1261.4786661793435\n","torch.Size([8, 1, 17])\n","tensor(462.0851, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.8412, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 3, iter 220: 546.2005304666977\n","torch.Size([8, 1, 17])\n","tensor(758.0855, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(4.9684, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 3, iter 240: 1254.9236605478973\n","torch.Size([8, 1, 17])\n","tensor(478.3401, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(1.0747, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 3, iter 260: 585.8126544734431\n","torch.Size([8, 1, 17])\n","tensor(654.3848, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(1.1680, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 3, iter 280: 771.1862477736972\n","torch.Size([8, 1, 17])\n","tensor(408.7083, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(3.4598, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 3, iter 300: 754.6891850309266\n","torch.Size([8, 1, 17])\n","tensor(609.1087, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0417, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 3, iter 320: 613.2738351853616\n","torch.Size([8, 1, 17])\n","tensor(955.4590, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(6.4037, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 3, iter 340: 1595.8252914339014\n","torch.Size([8, 1, 17])\n","tensor(6869.5657, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(17.6387, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 3, iter 360: 8633.437572423518\n","torch.Size([8, 1, 17])\n","tensor(1630.6760, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(4.8616, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 4, iter 0: 2116.8336663210353\n","torch.Size([8, 1, 17])\n","tensor(597.6384, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0751, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 4, iter 20: 605.1482604138123\n","torch.Size([8, 1, 17])\n","tensor(1631.1853, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.4740, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 4, iter 40: 1678.5899929888758\n","torch.Size([8, 1, 17])\n","tensor(2594.7227, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(3.3240, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 4, iter 60: 2927.119731781606\n","torch.Size([8, 1, 17])\n","tensor(452.8286, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(6.6793, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 4, iter 80: 1120.7573744764102\n","torch.Size([8, 1, 17])\n","tensor(755.8931, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.9415, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 4, iter 100: 850.0455657293166\n","torch.Size([8, 1, 17])\n","tensor(1549.9031, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(6.9005, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 4, iter 120: 2239.953484259691\n","torch.Size([8, 1, 17])\n","tensor(347.4670, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(1.0586, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 4, iter 140: 453.33182954207234\n","torch.Size([8, 1, 17])\n","tensor(1415.2934, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(5.0677, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 4, iter 160: 1922.0664523358087\n","torch.Size([8, 1, 17])\n","tensor(595.3341, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(5.4215, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 4, iter 180: 1137.4791886134851\n","torch.Size([8, 1, 17])\n","tensor(535.9710, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(8.2201, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 4, iter 200: 1357.9858801688226\n","torch.Size([8, 1, 17])\n","tensor(1699.3505, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(1.9308, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 4, iter 220: 1892.4346562156643\n","torch.Size([8, 1, 17])\n","tensor(1707.7128, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(11.0455, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 4, iter 240: 2812.2632037308995\n","torch.Size([8, 1, 17])\n","tensor(1178.7736, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.6854, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 4, iter 260: 1247.3098974206134\n","torch.Size([8, 1, 17])\n","tensor(1219.7632, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(4.9741, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 4, iter 280: 1717.17694808525\n","torch.Size([8, 1, 17])\n","tensor(315.4775, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.8823, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 4, iter 300: 403.7071804430796\n","torch.Size([8, 1, 17])\n","tensor(3164.3458, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(2.6477, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 4, iter 320: 3429.1167998736664\n","torch.Size([8, 1, 17])\n","tensor(331.3754, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(1.0698, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 4, iter 340: 438.35159846049254\n","torch.Size([8, 1, 17])\n","tensor(477.1608, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(3.4159, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 4, iter 360: 818.7543544007121\n","torch.Size([8, 1, 17])\n","tensor(3665.7971, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(2.9410, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 5, iter 0: 3959.8929032710284\n","torch.Size([8, 1, 17])\n","tensor(3525.7362, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(11.7362, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 5, iter 20: 4699.358793168893\n","torch.Size([8, 1, 17])\n","tensor(356.1370, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.5868, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 5, iter 40: 414.8124346148916\n","torch.Size([8, 1, 17])\n","tensor(531.4039, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(3.5866, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 5, iter 60: 890.0677620159075\n","torch.Size([8, 1, 17])\n","tensor(1011.6384, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(5.9113, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 5, iter 80: 1602.7668417576542\n","torch.Size([8, 1, 17])\n","tensor(1100.8186, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(2.3675, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 5, iter 100: 1337.5701177831493\n","torch.Size([8, 1, 17])\n","tensor(2027.5657, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(10.7454, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 5, iter 120: 3102.1084481786856\n","torch.Size([8, 1, 17])\n","tensor(521.4644, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.9546, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 5, iter 140: 616.9257075501661\n","torch.Size([8, 1, 17])\n","tensor(2018.0108, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(2.9453, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 5, iter 160: 2312.5389808129657\n","torch.Size([8, 1, 17])\n","tensor(368.0749, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(2.0173, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 5, iter 180: 569.8067037858384\n","torch.Size([8, 1, 17])\n","tensor(491.0527, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(1.4564, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 5, iter 200: 636.6926262238612\n","torch.Size([8, 1, 17])\n","tensor(685.3306, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(17.8153, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 5, iter 220: 2466.8613863070386\n","torch.Size([8, 1, 17])\n","tensor(507.3748, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(1.7284, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 5, iter 240: 680.2120054790946\n","torch.Size([8, 1, 17])\n","tensor(498.3248, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.3660, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 5, iter 260: 534.9212107185647\n","torch.Size([8, 1, 17])\n","tensor(407.7968, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(5.7374, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 5, iter 280: 981.5364992899094\n","torch.Size([8, 1, 17])\n","tensor(375.7142, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0736, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 5, iter 300: 383.07221962792596\n","torch.Size([8, 1, 17])\n","tensor(643.1220, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(4.8673, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 5, iter 320: 1129.8566043130118\n","torch.Size([8, 1, 17])\n","tensor(930.2034, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.2800, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 5, iter 340: 958.1986639939839\n","torch.Size([8, 1, 17])\n","tensor(2763.6436, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(8.9363, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 5, iter 360: 3657.2772940406753\n","torch.Size([8, 1, 17])\n","tensor(1635.8926, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(4.8069, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 6, iter 0: 2116.5844582661216\n","torch.Size([8, 1, 17])\n","tensor(1187.2307, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(1.1056, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 6, iter 20: 1297.7866214368337\n","torch.Size([8, 1, 17])\n","tensor(1085.0147, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(1.5190, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 6, iter 40: 1236.912762145881\n","torch.Size([8, 1, 17])\n","tensor(419.9067, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.1948, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 6, iter 60: 439.38706975289534\n","torch.Size([8, 1, 17])\n","tensor(920.4745, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.4439, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 6, iter 80: 964.863786720851\n","torch.Size([8, 1, 17])\n","tensor(816.8216, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0791, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 6, iter 100: 824.728227340617\n","torch.Size([8, 1, 17])\n","tensor(2640.1975, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(5.0180, device='cuda:0', grad_fn=<AddBackward0>)\n","epoch 6, iter 120: 3141.994404017202\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-e93a04b92796>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBoundingBoxModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidationloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-119bed9b2849>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, trainloader, validationloader, batch_size, version)\u001b[0m\n\u001b[1;32m     61\u001b[0m           \u001b[0mlabel_batch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mce_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatched_targ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist_batch_loss\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mlmbda\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlabel_batch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mprevious_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 1784) is killed by signal: Killed. "]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1000x1000 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"bKi0KkX9vLci","colab_type":"code","colab":{}},"source":["i = 0\n","for sample, target, road_image, extra in trainloader:\n","          optimizer.zero_grad()\n","          batch = torch.stack(sample).permute(1, 0, 2, 3, 4)\n","          batch = batch.to(device)\n","          if i % 100 == 0:\n","              print(target)\n","          i += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j1RwTl33vhAk","colab_type":"code","colab":{}},"source":["chkpnt = torch.load('/content/drive/My Drive/1008-competition/model_run/BoundingBoxModel/detect_version-1_epoch-43.pth', map_location=device)\n","chkpnt.keys()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UweYaaTmvcB7","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","\n","#Plot\n","fig = plt.figure()\n","fig.set_size_inches(6,4)\n","\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Performance')\n","plt.legend(loc='best')\n","\n","plt.savefig('/content/drive/My Drive/1008-competition/BoundingBoxModelResults-Total.png')\n","plt.show()"],"execution_count":0,"outputs":[]}]}